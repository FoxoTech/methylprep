import sys
import numpy as np
import pandas as pd
from pathlib import Path
# App
from methylprep.processing import pipeline
from methylprep.utils.files import download_file
#patching
import unittest
try:
    # python 3.4+ should use builtin unittest.mock not mock package
    from unittest.mock import patch
except ImportError:
    from mock import patch


class TestPipeline():

    @staticmethod
    def test_run_pipeline_all():
        """ check that we get back useful data.
        check that output files exist, then remove them."""
        test_data_dir = 'docs/example_data/GSE69852'
        test_outputs = [
            Path(test_data_dir, 'control_probes.pkl'),
            Path(test_data_dir, 'beta_values.pkl'),
            Path(test_data_dir, 'm_values.pkl'),
            Path(test_data_dir, 'meth_values.pkl'),
            Path(test_data_dir, 'unmeth_values.pkl'),
            Path(test_data_dir, 'noob_meth_values.pkl'),
            Path(test_data_dir, 'noob_unmeth_values.pkl'),
            Path(test_data_dir, 'sample_sheet_meta_data.pkl'),
            Path(test_data_dir, '9247377085', '9247377085_R04C02_processed.csv'),
            Path(test_data_dir, '9247377093', '9247377093_R02C01_processed.csv'),
            ]
        for outfile in test_outputs:
            if outfile.exists():
                outfile.unlink()

        beta_df = pipeline.run_pipeline(test_data_dir, export=True, save_uncorrected=True, save_control=True, betas=True, m_value=True, batch_size=None)
        for outfile in test_outputs:
            if not outfile.exists():
                raise FileNotFoundError(f"Expected {outfile.name} to be generated by run_pipeline() but it was missing.")
            else:
                print('+', outfile)
                outfile.unlink()

    @staticmethod
    def test_run_pipeline_demo_containers():
        """ check that we get back useful data.
        check that output files exist, then remove them."""
        test_data_dir = 'docs/example_data/GSE69852'
        test_data_containers = pipeline.run_pipeline(test_data_dir, sesame=False)
        print('containers:', test_data_containers)

        # spot checking the output.
        #if not test_data_containers[1].unmethylated.data_frame.iloc[0]['mean_value'] == 2712:
        if not np.isclose(test_data_containers[1]._SampleDataContainer__data_frame.iloc[0]['m_value'], -1.1347262, atol=0.01):
            raise AssertionError()
        #if not np.isclose(test_data_containers[1].unmethylated.data_frame.iloc[0]['noob'], 4479.96501260212):
        if not np.isclose(test_data_containers[1]._SampleDataContainer__data_frame.iloc[0]['noob_unmeth'], 4480.919922, atol=1.0):
            raise AssertionError()

    @staticmethod
    def test_run_pipeline_with_create_sample_sheet():
        test_data_dir = 'docs/example_data/epic_plus'
        test_data_containers = pipeline.run_pipeline(test_data_dir, export=False, sample_name=['Sample_1'],
            meta_data_frame=False, make_sample_sheet=True, sesame=False)
        # spot checking the output.
        if not np.isclose(test_data_containers[0]._SampleDataContainer__data_frame.iloc[0]['noob_meth'], 1180.22998046875, atol=1.0):
            print(test_data_containers[0]._SampleDataContainer__data_frame)
            raise AssertionError(f"{test_data_containers[0]._SampleDataContainer__data_frame.iloc[0]['noob_meth']} vs {1180.2299}")
        if not np.isclose(test_data_containers[0]._SampleDataContainer__data_frame.iloc[0]['beta_value'], 0.759056, atol=0.01):
            raise AssertionError()

    @staticmethod
    def test_download_manifest_dummy_file():
        """ will download a tiny file from the array-manifest-files s3 bucket, to test the SSL connection on all platforms.
        The dummy file is not a proper manifest CSV, so doesn't test format.
        download_file now defaults to non-SSL if SSL fails, with warning to user."""
        test_filename = 'unittest.txt'
        test_s3_bucket = 'https://array-manifest-files.s3.amazonaws.com'  # 's3://array-manifest-files'
        dest_dir = ''
        # use the .download_file() method in files.py to test the download step specifically. this is called by Manifests() class.
        download_file(test_filename, test_s3_bucket, dest_dir, overwrite=False)
        # in testing mode, this should not exist, and should get deleted right after each successful test.
        if not Path(dest_dir,test_filename).is_file():
            raise AssertionError()
        Path(dest_dir,test_filename).unlink() # deletes file.

    @staticmethod
    def test_pipeline_two_samples():
        """ pass in --sample_name with 2 samples -- from fake command line args """
        test_data_dir = 'docs/example_data/GSE69852'
        testargs = ["__program__", '-d', test_data_dir, '--no_export', '--sample_name', 'AdultLiver1', 'FetalLiver1']
        with patch.object(sys, 'argv', testargs):
            test_data_containers = pipeline.run_pipeline(test_data_dir, sesame=False)
            # spot checking the output.
            #if not test_data_containers[1].unmethylated.data_frame.iloc[0]['mean_value'] == 2712:
            #if not test_data_containers[1]._SampleDataContainer__data_frame.iloc[0]['unmeth'] == 2712:
            #    raise AssertionError()
            if not np.isclose(test_data_containers[1]._SampleDataContainer__data_frame.iloc[0]['noob_unmeth'], 4480.919922, atol=1.0):
                raise AssertionError()

    @staticmethod
    def test_run_pipeline_export_data():
        """ check that we get back useful data with --export option """
        test_data_dir = 'docs/example_data/GSE69852'
        testfile_1 = Path(test_data_dir, '9247377093', '9247377093_R02C01_processed.csv')
        testfile_2 = Path(test_data_dir, '9247377085', '9247377085_R04C02_processed.csv')
        if testfile_1.exists():
            testfile_1.unlink()
        if testfile_2.exists():
            testfile_2.unlink()
        test_data_containers = pipeline.run_pipeline(test_data_dir, export=True, sesame=False)
        if not testfile_1.exists():
            raise AssertionError("no exported processed csv found")

        test1 = pd.read_csv(testfile_1)
        if test1['beta_value'].isna().sum() > 0:
            print(test1.head())
            raise AssertionError('missing values in processed csv')
        test2 = pd.read_csv(testfile_2)
        if test2['beta_value'].isna().sum() > 0:
            print(test2.head())
            raise AssertionError('missing values in processed csv')

        # spot checking the output.
        if not np.isclose(test_data_containers[1]._SampleDataContainer__data_frame.iloc[0]['beta_value'], 0.30799999, atol=0.01):
            print(test_data_containers[1]._SampleDataContainer__data_frame)
            raise AssertionError(f"{test_data_containers[1]._SampleDataContainer__data_frame.iloc[0]['beta_value']} vs {0.30799999}")
        # spot checking the output.
        total_nas = test_data_containers[0]._SampleDataContainer__data_frame['beta_value'].isna().sum()
        if total_nas > 0:
            print(f'found {total_nas} missing beta_values (N/A or inf) in sample')
            raise AssertionError()
        if not np.isclose(test_data_containers[1]._SampleDataContainer__data_frame.iloc[3]['noob_meth'], 3811.0, atol=1.0):
            raise AssertionError(f"{test_data_containers[1]._SampleDataContainer__data_frame.iloc[3]['noob_meth']} vs {3811.162109}")

    @staticmethod
    def test_run_pipeline_sesame_defaults():
        """ check that we get back useful data.
        checks SDC, CSV outputs, and pickles after sesame=True processing
        check that output files exist, then remove them.
        """
        test_data_dir = 'docs/example_data/GSE69852'
        test_outputs = [
            Path(test_data_dir, 'control_probes.pkl'),
            Path(test_data_dir, 'beta_values.pkl'),
            Path(test_data_dir, 'm_values.pkl'),
            Path(test_data_dir, 'meth_values.pkl'),
            Path(test_data_dir, 'unmeth_values.pkl'),
            Path(test_data_dir, 'noob_meth_values.pkl'),
            Path(test_data_dir, 'noob_unmeth_values.pkl'),
            Path(test_data_dir, 'sample_sheet_meta_data.pkl'),
            Path(test_data_dir, '9247377085', '9247377085_R04C02_processed.csv'),
            Path(test_data_dir, '9247377093', '9247377093_R02C01_processed.csv'),
            ]
        for outfile in test_outputs:
            if outfile.exists():
                outfile.unlink()

        test_data_containers = pipeline.run_pipeline(test_data_dir, sesame=True, export=True)
        test_probes = ['cg00063477', 'cg00121626', 'cg00223952', 'cg27614706', 'cg27619353', 'cg27620176', 'cg27647370', 'cg27652464']
        # for version 1.4.0
        minfi_reference_data = [
            ['cg00035864',     2040.0,       4480.0,    0.308157, -1.134930],
            ['cg00061679',     5946.0,       5276.0,    0.525172,  0.172475],
            ['cg00063477',     5759.0,        315.0,    0.932783,  4.192395],
            ['cg00121626',     3811.0,       7636.0,    0.330042, -1.002648],
            ['cg00223952',      277.0,      12107.0,    0.022188, -5.449811],
            ['cg27614706',     5831.0,        265.0,    0.941091,  4.459679],
            ['cg27619353',     7466.0,      14894.0,    0.332413, -0.996324],
            ['cg27620176',    11753.0,        222.0,    0.973333,  5.726326],
            ['cg27647370',    15752.0,       2212.0,    0.872011,  2.832112],
            ['cg27652464',      656.0,      15224.0,    0.041051, -4.536508],
        ]
        minfi_ref = pd.DataFrame(minfi_reference_data, columns=['IlmnID','noob_meth','noob_unmeth','beta_value','m_value']).set_index('IlmnID')
        NaN = np.nan # this matches '9247377093_R02C01'
        reference_data_old_noob = [
            ['cg00063477',     4107.0,        172.0,           1.0,       0.960,    4.578],
            ['cg00121626',     3542.0,       3397.0,           1.0,       0.510,    0.060],
            ['cg00223952',        NaN,          NaN,           NaN,         NaN,      NaN],
            ['cg27614706',        NaN,          NaN,           NaN,         NaN,      NaN],
            ['cg27619353',     2226.0,       9714.0,           1.0,       0.186,   -2.126],
            ['cg27620176',     6057.0,         94.0,           1.0,       0.985,    6.010],
            ['cg27647370',     8897.0,        167.0,           1.0,       0.982,    5.735],
            ['cg27652464',      398.0,       8832.0,           1.0,       0.043,   -4.472],
        ]
        reference_data = [ #CSV file
            ['cg00063477',     4115.0,        172.0,           1.0,       0.960,    4.580],
            ['cg00121626',     3552.0,       3381.0,           1.0,       0.512,    0.071],
            ['cg00223952',      420.0,       7058.0,           0.0,       0.056,   -4.071],
            ['cg27614706',     3612.0,         90.0,           0.0,       0.976,    5.327],
            ['cg27619353',     2204.0,       9713.0,           1.0,       0.185,   -2.140],
            ['cg27620176',     6052.0,         94.0,           1.0,       0.985,    6.010],
            ['cg27647370',     8895.0,        167.0,           1.0,       0.982,    5.735],
            ['cg27652464',      396.0,       8829.0,           1.0,       0.043,   -4.479],
        ]
        reference_container_data = [
            ['cg00063477',     4115.0,        172.0,           1.0,       0.960,    4.580],
            ['cg00121626',     3552.0,       3381.0,           1.0,       0.512,    0.071],
            ['cg00223952',        NaN,          NaN,           NaN,       0.056,   -4.071],
            ['cg27614706',        NaN,          NaN,           NaN,       0.976,    5.327],
            ['cg27619353',     2204.0,       9713.0,           1.0,       0.185,   -2.140],
            ['cg27620176',     6052.0,         94.0,           1.0,       0.985,    6.010],
            ['cg27647370',     8895.0,        167.0,           1.0,       0.982,    5.735],
            ['cg27652464',      396.0,       8829.0,           1.0,       0.043,   -4.479],
        ]

        ref = pd.DataFrame(reference_data, columns=['IlmnID','noob_meth','noob_unmeth','quality_mask','beta_value','m_value']).set_index('IlmnID')
        container_ref = pd.DataFrame(reference_container_data, columns=['IlmnID','noob_meth','noob_unmeth','quality_mask','beta_value','m_value']).set_index('IlmnID')
        # checking outputs.
        idata = test_data_containers[0]._SampleDataContainer__data_frame.index
        iref = ref.index
        subdata = test_data_containers[0]._SampleDataContainer__data_frame[idata.isin(iref)]
        meth = all(np.isclose(subdata[['noob_meth']], container_ref[['noob_meth']], atol=1.0, equal_nan=True))
        unmeth = all(np.isclose(subdata[['noob_unmeth']], container_ref[['noob_unmeth']], atol=1.0, equal_nan=True))
        beta = all(np.isclose(subdata[['beta_value']], ref[['beta_value']], atol=0.01, equal_nan=True))
        m = all(np.isclose(subdata[['m_value']], ref[['m_value']], atol=0.01, equal_nan=True))
        if meth is False:
            raise AssertionError(f"container meth values don't match in data container:\n{subdata[['noob_meth']]}\n{container_ref[['noob_meth']]}")
        if unmeth is False:
            raise AssertionError(f"container unmeth values don't match in data container:\n{subdata[['noob_unmeth']]}\n{container_ref[['noob_unmeth']]}")
        if beta is False:
            raise AssertionError(f"container beta values don't match in data container")
        if m is False:
            raise AssertionError(f"container m values don't match in data container")

        csv_ref = pd.DataFrame(reference_data, columns=['IlmnID','noob_meth','noob_unmeth','quality_mask','beta_value','m_value']).set_index('IlmnID')
        csv_ref = csv_ref[ csv_ref.index.isin(test_probes)]
        csv_data = pd.read_csv(Path(test_data_dir, '9247377093', '9247377093_R02C01_processed.csv')).set_index('IlmnID')
        csv_data = csv_data[ csv_data.index.isin(test_probes)]
        csv_meth = all(np.isclose(csv_data[['noob_meth']], csv_ref[['noob_meth']], atol=1.0, equal_nan=True))
        csv_unmeth = all(np.isclose(csv_data[['noob_unmeth']], csv_ref[['noob_unmeth']], atol=1.0, equal_nan=True))
        csv_beta = all(np.isclose(csv_data[['beta_value']], csv_ref[['beta_value']], atol=0.01, equal_nan=True))
        csv_m = all(np.isclose(csv_data[['m_value']], csv_ref[['m_value']], atol=0.01, equal_nan=True))
        if csv_meth is False:
            raise AssertionError(f"csv meth values don't match in data container:\n{csv_data[['noob_meth']]}\n{csv_ref[['noob_meth']]}")
        if csv_unmeth is False:
            raise AssertionError(f"csv unmeth values don't match in data container:\n{csv_data[['noob_unmeth']]}\n{csv_ref[['noob_unmeth']]}")
        if csv_beta is False:
            raise AssertionError(f"csv beta values don't match in data container")
        if csv_m is False:
            raise AssertionError(f"csv m values don't match in data container")

        #beta = pd.read_pickle(Path(test_data_dir, 'beta_values.pkl'))
        noob_meth = pd.read_pickle(Path(test_data_dir, 'noob_meth_values.pkl'))
        noob_unmeth = pd.read_pickle(Path(test_data_dir, 'noob_unmeth_values.pkl'))
        ref_meth = [
            ['cg00000029',                   2231],
            ['cg00000108',                   7880],
            ['cg00000109',                   3516],
            ['cg00000165',                    344],
            ['cg00000236',                   3601],
        ]
        ref_meth = pd.DataFrame(ref_meth, columns = ['IlmnID', '9247377085_R04C02']).set_index('IlmnID')
        test_noob_meth = noob_meth['9247377085_R04C02'][noob_meth.index.isin(ref_meth.index)]
        meth = all(np.isclose(test_noob_meth, ref_meth['9247377085_R04C02'], atol=1.0, equal_nan=True))
        if meth is False:
            raise AssertionError("meth values don't match in pickle")

        test_data_dir = 'docs/example_data/GSE69852'
        test_outputs = [
            Path(test_data_dir, 'control_probes.pkl'),
            Path(test_data_dir, 'beta_values.pkl'),
            Path(test_data_dir, 'm_values.pkl'),
            Path(test_data_dir, 'meth_values.pkl'),
            Path(test_data_dir, 'unmeth_values.pkl'),
            Path(test_data_dir, 'noob_meth_values.pkl'),
            Path(test_data_dir, 'noob_unmeth_values.pkl'),
            Path(test_data_dir, 'sample_sheet_meta_data.pkl'),
            Path(test_data_dir, '9247377085', '9247377085_R04C02_processed.csv'),
            Path(test_data_dir, '9247377093', '9247377093_R02C01_processed.csv'),
            ]
        for outfile in test_outputs:
            if outfile.exists():
                outfile.unlink()

    @staticmethod
    def test_process_mouse():
        """ catches anything serious broken about mouse array processing
        in v1.4.4 / v0.7.4 I expect this to use the linear dye fallback within the sesame method, because of dupe probe names."""
        PATH = 'docs/example_data/mouse'
        ID = '204879580038_R06C02'
        print('* loading mouse manifest')
        import methylprep
        manifest = methylprep.files.Manifest(methylprep.models.ArrayType('mouse'))
        print('* loading one idat pair of files')
        green_filepath = Path(PATH, f'{ID}_Grn.idat') #'204879580038_R06C02_Grn.idat')
        red_filepath = Path(PATH, f'{ID}_Red.idat') #'204879580038_R06C02_Red.idat')
        print(f"* GREEN --> {green_filepath.name}")
        print(f"* RED --> {red_filepath.name}")
        if not (green_filepath.exists() and green_filepath.is_file()):
            raise FileNotFoundError("mouse test data missing")
        if not (red_filepath.exists() and red_filepath.is_file()):
            raise FileNotFoundError("mouse test data missing")
        files_to_remove = ['samplesheet.csv', 'control_probes.pkl', 'mouse_probes.pkl',
            'sample_sheet_meta_data.pkl', 'noob_meth_values.pkl', 'noob_unmeth_values.pkl']
        for _file in files_to_remove:
            if Path(PATH, _file).is_file():
                Path(PATH, _file).unlink()
        data = methylprep.run_pipeline(PATH, make_sample_sheet=True)
        df = data[0]._SampleDataContainer__data_frame
        #print( np.isclose(list(df['beta_value'][:3]), [0.905712,  0.841185,  0.129731]) )
        #assert np.isclose(list(df['beta_value'][:3]), [0.905712,  0.841185,  0.129731]).all() == True
        for _file in files_to_remove:
            if Path(PATH, _file).is_file():
                Path(PATH, _file).unlink()


class UnitTestCase(unittest.TestCase):
    def test_pipeline_wrong_sample_name_fails(self):
        LOCAL = Path('docs/example_data/GSE69852/')
        with self.assertRaises(SystemExit):
            pipeline.run_pipeline(LOCAL, betas=True, sample_name=['blahblah_wrong_sample_name'])
