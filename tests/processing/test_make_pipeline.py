import sys
import numpy as np
import pandas as pd
from pathlib import Path
import shutil
# App
from methylprep.processing import make_pipeline, run_pipeline
from methylprep.utils.files import download_file
#patching
try:
    # python 3.4+ should use builtin unittest.mock not mock package
    from unittest.mock import patch
except ImportError:
    from mock import patch


class TestMakePipeline():
    test_data_dir = 'docs/example_data/GSE69852'

    def clean_dir(self, other_dir=None):
        test_data_dir = self.test_data_dir if other_dir == None else other_dir
        test_outputs = [
            Path(test_data_dir, 'control_probes.pkl'),
            Path(test_data_dir, 'beta_values.pkl'),
            Path(test_data_dir, 'm_values.pkl'),
            Path(test_data_dir, 'meth_values.pkl'),
            Path(test_data_dir, 'unmeth_values.pkl'),
            Path(test_data_dir, 'noob_meth_values.pkl'),
            Path(test_data_dir, 'noob_unmeth_values.pkl'),
            Path(test_data_dir, 'sample_sheet_meta_data.pkl'),
            Path(test_data_dir, 'poobah_values.pkl'),
            Path(test_data_dir, '9247377085', '9247377085_R04C02_processed.csv'),
            Path(test_data_dir, '9247377093', '9247377093_R02C01_processed.csv'),
            ]
        for outfile in test_outputs:
            if outfile.exists():
                outfile.unlink()

    def test_make_pipeline_sesame_steps_vs_all(self):
        """
        - check that we get back useful data.
        - compare sesame=True with a list of equivalent steps
        check that output files exist, then remove them."""
        self.clean_dir()
        alt_data_dir = 'docs/example_data/GSE69852_alt'
        copy_files = [
            '9247377093_R02C01_Red.idat',
            '9247377093_R02C01_Grn.idat',
            '9247377085_R04C02_Red.idat',
            '9247377085_R04C02_Grn.idat',
            'samplesheet.csv']

        if not Path(alt_data_dir).exists():
            Path(alt_data_dir).mkdir()
        for copy_file in copy_files:
            if not Path(alt_data_dir,copy_file).exists():
                shutil.copy(Path(self.test_data_dir, copy_file), Path(alt_data_dir, copy_file))

        df1 = make_pipeline(self.test_data_dir,
            steps=['all'],
            exports=['all'],
            estimator='betas')

        df2 = make_pipeline(alt_data_dir,
            steps=['infer_channel_switch', 'poobah', 'quality_mask', 'noob', 'dye_bias'],
            exports=['all'],
            estimator='betas')

        test_outputs = [
            'control_probes.pkl',
            'beta_values.pkl',
            'meth_values.pkl',
            'unmeth_values.pkl',
            'noob_meth_values.pkl',
            'noob_unmeth_values.pkl',
            'sample_sheet_meta_data.pkl',
            'poobah_values.pkl',
            Path('9247377085', '9247377085_R04C02_processed.csv'),
            Path('9247377093', '9247377093_R02C01_processed.csv'),
            ]

        assert df1.equals(df2)

        # verify outputs all exist
        for outfile in test_outputs:
            filepath = Path(self.test_data_dir, outfile)
            if not filepath.exists():
                raise FileNotFoundError(f"Expected {filepath.name} to be generated by run_pipeline() but it was missing.")
            else:
                print('+', outfile)
                #outfile.unlink()
        for outfile in test_outputs:
            filepath = Path(alt_data_dir, outfile)
            if not filepath.exists():
                raise FileNotFoundError(f"Expected {filepath.name} to be generated by run_pipeline() but it was missing.")
            else:
                print('+', outfile)
                #outfile.unlink()

        # compare output files to ensure they match each other
        for outfile in test_outputs:
            filepath1 = Path(self.test_data_dir, outfile)
            filepath2 = Path(alt_data_dir, outfile)
            if filepath1.suffix in ('.pkl','.csv'):
                if filepath1.suffix == '.pkl':
                    df1 = pd.read_pickle(filepath1)
                    df2 = pd.read_pickle(filepath2)
                elif filepath1.suffix == '.csv':
                    df1 = pd.read_csv(filepath1)
                    df2 = pd.read_csv(filepath2)
                if isinstance(df1, pd.DataFrame) and isinstance(df2, pd.DataFrame):
                    assert df1.equals(df2)
                    print(f"{outfile}: df1 equals df2: {df1.equals(df2)}")
                elif isinstance(df1, dict) and isinstance(df2, dict):
                    # control, mouse probes are dict of dataframes; assume save length
                    for i in range(len(df1)):
                        dfa = list(df1.values())[i]
                        dfb = list(df2.values())[i]
                        assert dfa.equals(dfb)
                        print(f"{outfile}, sample[{i}]: df1 equals df2: {dfa.equals(dfb)}")
                else:
                    raise ValueError("unknown/mismatched output")

        # match run_pipeline to make_pipeline for basic sesame
        shutil.rmtree(Path(alt_data_dir))
        if not Path(alt_data_dir).exists():
            Path(alt_data_dir).mkdir()
        for copy_file in copy_files:
            if not Path(alt_data_dir,copy_file).exists():
                shutil.copy(Path(self.test_data_dir, copy_file), Path(alt_data_dir, copy_file))

        df2 = run_pipeline(alt_data_dir,
            sesame=True,
            betas=True,
            poobah=True, # sesame sets this
            export_poobah=True,
            save_uncorrected=True,
            save_control=True,
            export=True, #CSV
            )

        # compare output files to ensure they match each other
        # passes: control, meth, unmeth
        failed = []
        for outfile in test_outputs:
            filepath1 = Path(self.test_data_dir, outfile)
            filepath2 = Path(alt_data_dir, outfile)
            if filepath1.suffix in ('.pkl','.csv'):
                if filepath1.suffix == '.pkl':
                    df1 = pd.read_pickle(filepath1)
                    df2 = pd.read_pickle(filepath2)
                elif filepath1.suffix == '.csv':
                    df1 = pd.read_csv(filepath1)
                    df2 = pd.read_csv(filepath2)
                if isinstance(df1, pd.DataFrame) and isinstance(df2, pd.DataFrame):
                    if not df1.equals(df2):
                        failed.append(f"{outfile} FAILED to match {df1.equals(df2)}")
                    else:
                        print(f"{outfile}: df1 equals df2: {df1.equals(df2)}")
                elif isinstance(df1, dict) and isinstance(df2, dict):
                    # control, mouse probes are dict of dataframes; assume save length
                    for i in range(len(df1)):
                        dfa = list(df1.values())[i]
                        dfb = list(df2.values())[i]
                        assert dfa.equals(dfb)
                        print(f"run vs make pipeline: {outfile}, sample[{i}]: df1 equals df2: {dfa.equals(dfb)}")
                else:
                    raise ValueError("unknown/mismatched output")
        # reset
        shutil.rmtree(Path(alt_data_dir))
        self.clean_dir()

        if failed:
            for test in failed:
                print(test)
            raise AssertionError("One or more tests failed")


    @staticmethod
    def test_make_pipeline_m_value_mouse():
        """covering all of the code gaps here.
        TODO: add steps=[] -- currently broken"""
        source_data_dir = 'docs/example_data/mouse'
        test_data_dir = 'docs/example_data/mouse_test'
        # copy files first
        Path(test_data_dir).mkdir(exist_ok=True)
        copy_files = ['204879580038_R06C02_Red.idat','204879580038_R06C02_Grn.idat','samplesheet.csv']
        for copy_file in copy_files:
            shutil.copy(Path(source_data_dir, copy_file), Path(test_data_dir, copy_file))
        m_values = make_pipeline(test_data_dir, steps=['noob'], exports=[], estimator='m_value', save_control=False, save_uncorrected=False)
        ref_m_values = pd.DataFrame(data=[
            ['cg00101675_BC21',              3.245756],
            ['cg00116289_BC21',              3.888049],
            ['cg00211372_TC21',              2.876011],
            ['cg00531009_BC21',              3.239251],
            ['cg00747726_TC21',              2.386080],
            ['uk9978_TC11',                  0.415037],
            ['uk9983_TC21',                 -0.540568],
            ['uk9986_BC11',                 -0.673190],
            ['uk998926237_TC11',            -0.230006],
            ['uk9995_TC11',                  0.330645],
            ], columns=['IlmnID','204879580038_R06C02']).set_index('IlmnID')
        sub_data = m_values[ m_values.index.isin(ref_m_values.index) ]
        if np.allclose(sub_data, ref_m_values, atol=1e-6) is False:
            raise AssertionError(f"m_values don't match ref values for one mouse sample: ref {ref_m_values} vs {sub_data}")
        # partial lists, m_value output, run_pipeline matches make_pipeline
        test_outputs = [
            Path(test_data_dir, 'm_values.pkl'),
            Path(test_data_dir, 'noob_meth_values.pkl'),
            Path(test_data_dir, 'noob_unmeth_values.pkl')
            ]
        for outfile in test_outputs:
            if not outfile.exists():
                raise FileNotFoundError(f"Expected {outfile.name} to be generated by run_pipeline() but it was missing.")
            else:
                outfile.unlink()
        try:
            shutil.rmtree(test_data_dir)
        except OSError as e:
            print("Error: %s : %s" % (dir_path, e.strerror))
